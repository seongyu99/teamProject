import numpy as np, cv2
import tensorflow as tf
import pathlib

train_dir = pathlib.Path("C:/Users/PC/Desktop/faces/train")
test_dir = pathlib.Path("C:/Users/PC/Desktop/faces/train")

batch_size = 32
img_height = 180
img_width = 180

train_ds = tf.keras.utils.image_dataset_from_directory(
  train_dir,
  validation_split=0.2,
  subset="training",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)
val_ds = tf.keras.utils.image_dataset_from_directory(
  train_dir,
  validation_split=0.2,
  subset="validation",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)
test_ds = tf.keras.utils.image_dataset_from_directory(
  test_dir,
  image_size=(img_height, img_width),
  batch_size=batch_size)

class_names = train_ds.class_names
file_paths = train_ds.file_paths

num_classes = 1

model = tf.keras.Sequential([
  tf.keras.layers.experimental.preprocessing.Rescaling(1./255),
  tf.keras.layers.Conv2D(32, 3, activation='relu'),
  tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Conv2D(32, 3, activation='relu'),
  tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Conv2D(32, 3, activation='relu'),
  tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dense(num_classes)
])
model.compile(
  optimizer='adam',
  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),
  metrics=['accuracy'])
model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=20
)

loss, accuracy = model.evaluate(test_ds)
print("accuracy : ", accuracy, "\n")
print("loss : ", loss)

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
def face_detector(img, size=0.5):
  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
  faces = face_classifier.detectMultiScale(gray, 1.3, 5)
  if faces is ():
    return img, []
  for (x, y, w, h) in faces:
    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 255), 2)
    roi = img[y:y + h, x:x + w]
    roi = cv2.resize(roi, (200, 200))
  return img, roi  # 검출된 좌표에 사각 박스 그리고(img), 검출된 부위를 잘라(roi) 전달
model = cv2.face.LBPHFaceRecognizer_create()

#예측을 위한 이미지 리사이징 (매우 중요)
cap = cv2.VideoCapture(0)
while True:
  ret, frame = cap.read()
  image, face = face_detector(frame)
  try:
    face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)
    result = model.predict(face)
    print(result[1])
    similar = int(100 * (1))
    display_string = str(similar) + '% Confidence it is user'
    if similar > 75:
      cv2.putText(image, "Unlocked", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)
      cv2.imshow('Face Cropper', image)
    else:
      cv2.putText(image, "Locked", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2)
      cv2.imshow('Face Cropper', image)
  except:
    cv2.putText(image, "Face Not Found", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)
    cv2.imshow('Face Cropper', image)
    pass
  if cv2.waitKey(1) == 13:
    break

image1 = cv2.imread(face, cv2.IMREAD_COLOR)
image1 = cv2.resize(image1, (img_height, img_width))
image_array1 = tf.keras.preprocessing.image.img_to_array(image1)
image_array1 = tf.expand_dims(image_array1, 0)

prediction1 = model.predict(image_array1)
score1 = tf.nn.softmax(prediction1[0])
print("prediction1 : ",prediction1)
print("score1 : ",score1)
print(
    "This image most likely belongs to {} with a {:.2f} percent confidence."
    .format(class_names[np.argmax(score1)], 100 * np.max(score1))
)
